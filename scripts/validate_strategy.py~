
import pandas as pd
import numpy as np
from data import DataHandler
from strategy import StrategyFactory
from backtester import Backtester
from metrics import calculate_returns, calculate_metrics
from config import Config

def validate_backtest_pipeline():
    # Create a default config (can be extended to accept CLI or dict)
    class Args:
        data_file = 'path_to_your_data.csv'  # Replace with actual file
        top_n = 5
        start_date = None
        end_date = None
        train_size = 0.7
        strategy_name = "TopNStrategy"
        other_args = None

    config = Config(Args())

    # Load and preprocess data
    data_handler = DataHandler(config)
    data_handler.load_data()
    data_handler.preprocess()
    data_handler.split_data()

    # Create strategy and train
    strategy = StrategyFactory.create_strategy(config)
    strategy.train(data_handler.train_data)

    # Apply strategy to test data
    signals = strategy.rules.generate_signals(data_handler.test_data)
    data_handler.test_data['signal'] = signals

    # Calculate returns
    log_returns = np.log(data_handler.test_data['Close'] / data_handler.test_data['Close'].shift(1)).fillna(0)
    strat_returns = calculate_returns(signals, log_returns)

    # Evaluate metrics
    metrics = calculate_metrics(strat_returns)
    print("\n[Validation Report]")
    print("-" * 40)
    print("Sample Signals:")
    print(signals.head(10))
    print("\nPerformance Metrics:")
    for k, v in metrics.items():
        print(f"{k:20}: {v}")
    print("-" * 40)

if __name__ == "__main__":
    validate_backtest_pipeline()
